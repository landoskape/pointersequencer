{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52362dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pointer Immediate Tasks:\n",
    "- Run an experiment where I take trained pointer networks and transition them to a dominoe based value \n",
    "function and a gamma < 1, and show that they can learn to prioritize playing high value dominoes first. Then...\n",
    "-  Add the context vector that encodes the number of turns left (with uncertainty?)\n",
    "    - so the full pointer network will get an extra context input that describes how many turns are left\n",
    "    - 0 rewards will be given after the possible turns are over\n",
    "    - so the network will have to learn to get as much value out as quickly as possible\n",
    "-  Also apply these networks to the vehicle routing problem?\n",
    "-  Analyze encoding space of pointer networks...\n",
    "-  Do the encoder swap of different pointer layers...\n",
    "-  Does the speed of learning for the different networks on the sequencer task come from true performance or just sensitivity to the temperature? \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Add mechanism for printing the arguments used to build a pointernetwork so the user can see what they did. \n",
    "Add mechanism for storing hidden parameters to entire pointer network\n",
    "\n",
    "Add documentation of baseline updates and performance etc\n",
    "Add some dataset specific summary plots and integrate into plotting code? \n",
    "Get the supervised learning methods working for each dataset and task\n",
    "Checkpointing, figure making, logging, etc\n",
    "\n",
    "it worked!!! now trying without embedding bias...\n",
    "it works without embedding bias. It works (with different speeds per pointer layer!) with lower train temperature\n",
    " (but of course that could be because of differential sensitivity to temperature..., should test that directly)\n",
    "now trying with 1 encoding layer. \n",
    "\n",
    ":)\n",
    "\n",
    "\n",
    "TODO: \n",
    "DOMINOES SEQUENCER Comparison of max to real reward:\n",
    "- Add target to batch (can do post-hoc, even if not requested)\n",
    "- Measure reward of target\n",
    "- Add a 2D vector comparing max and real reward for each batch element!!\n",
    "\n",
    "TSP Distance Traveled:\n",
    "- Explicitly measure the distance traveled by the agent in the TSP task\n",
    "- Compare to Held-Karp Solution\n",
    "\n",
    "\n",
    "TODO ASAP!!!!!!\n",
    "I'm running experiments with attention only pointers and saving the networks. Will use trained networks\n",
    "to test some other dataset specific variables and plots, etc when they're finished, then integrate those\n",
    "into the main workflow. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Leaving this here to remind myself to check the work when the big run is done!\n",
    "# integrate scheduler into the \"make_train_parameters\" method of the experiment base class\n",
    "# for train_temperature especially!!!\n",
    "# -- just use scheduler from parser, and have a fallback for if \"{name}_scheduler\" isn't present --\n",
    "\n",
    "# think more carefully about how to handle the ignore index for reward computation.....\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "from time import time\n",
    "import torch\n",
    "from ptrseq.datasets import get_dataset\n",
    "from ptrseq.experiments import get_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78fe2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "train\n",
      "selection\n",
      "multimode\n",
      "available\n",
      "hand_size\n",
      "highest_dominoe\n",
      "train_fraction\n",
      "randomize_direction\n",
      "batch_size\n",
      "return_target\n",
      "ignore_index\n",
      "threads\n",
      "value_method\n",
      "value_multiplier\n",
      "target\n",
      "best_seq\n",
      "best_dir\n"
     ]
    }
   ],
   "source": [
    "task = \"dominoe_sequencer\"\n",
    "dataset = get_dataset(task, build=True, highest_dominoe=9, hand_size=10)\n",
    "batch = dataset.generate_batch(batch_size=4, return_target=True)\n",
    "\n",
    "for k in batch.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f70f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 7 to 6 with reward 0.15, distance: 0.15\n",
      "From 6 to 9 with reward 0.32, distance: 0.32\n",
      "From 9 to 0 with reward 0.34, distance: 0.34\n",
      "From 0 to 5 with reward 0.57, distance: 0.57\n",
      "From 5 to 8 with reward 0.29, distance: 0.29\n",
      "From 8 to 3 with reward 0.28, distance: 0.28\n",
      "From 3 to 2 with reward 0.56, distance: 0.56\n",
      "From 2 to 4 with reward 0.48, distance: 0.48\n",
      "From 4 to 1 with reward 0.40, distance: 0.40\n"
     ]
    }
   ],
   "source": [
    "reward = dataset.reward_function(batch[\"target\"], batch)\n",
    "\n",
    "ib = 0\n",
    "prev = batch[\"init\"][ib]\n",
    "for i, s in enumerate(batch[\"target\"][ib]):\n",
    "    if i==(batch[\"target\"].size(1)-1):\n",
    "        add_dist = batch[\"dists\"][ib][s, batch[\"init\"][ib]]\n",
    "    else:\n",
    "        add_dist = 0\n",
    "    print(f\"From {prev} to {s} with reward {-reward[ib][i]:.2f}, distance: {batch['dists'][ib][prev, s] + add_dist :.2f}\")\n",
    "    prev = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865fb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
