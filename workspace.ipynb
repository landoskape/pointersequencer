{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52362dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pointer Immediate Tasks:\n",
    "- Run an experiment where I take trained pointer networks and transition them to a dominoe based value \n",
    "function and a gamma < 1, and show that they can learn to prioritize playing high value dominoes first. Then...\n",
    "-  Add the context vector that encodes the number of turns left (with uncertainty?)\n",
    "    - so the full pointer network will get an extra context input that describes how many turns are left\n",
    "    - 0 rewards will be given after the possible turns are over\n",
    "    - so the network will have to learn to get as much value out as quickly as possible\n",
    "-  Also apply these networks to the vehicle routing problem?\n",
    "-  Analyze encoding space of pointer networks...\n",
    "-  Do the encoder swap of different pointer layers...\n",
    "-  Does the speed of learning for the different networks on the sequencer task come from true performance or just sensitivity to the temperature? \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "We can speed up some of the processing by doing all networks output in a list at once-- for example for reward computation. I think \n",
    "the sequencer is slower because measuring reward takes a long time...\n",
    "\n",
    "Add mechanism for printing the arguments used to build a pointernetwork so the user can see what they did. \n",
    "Add mechanism for storing hidden parameters to entire pointer network\n",
    "\n",
    "Add documentation of baseline updates and performance etc\n",
    "Add some dataset specific summary plots and integrate into plotting code? \n",
    "Get the supervised learning methods working for each dataset and task\n",
    "Checkpointing, figure making, logging, etc\n",
    "\n",
    "it worked!!! now trying without embedding bias...\n",
    "it works without embedding bias. It works (with different speeds per pointer layer!) with lower train temperature\n",
    " (but of course that could be because of differential sensitivity to temperature..., should test that directly)\n",
    "now trying with 1 encoding layer. \n",
    "\n",
    ":)\n",
    "\n",
    "TODO: \n",
    "DOMINOES SEQUENCER Comparison of max to real reward:\n",
    "- Add target to batch (can do post-hoc, even if not requested)\n",
    "- Measure reward of target\n",
    "- Add a 2D vector comparing max and real reward for each batch element!!\n",
    "\n",
    "TSP Distance Traveled:\n",
    "- Explicitly measure the distance traveled by the agent in the TSP task\n",
    "- Compare to Held-Karp Solution\n",
    "\n",
    "\n",
    "TODO ASAP!!!!!!\n",
    "I'm running experiments with attention only pointers and saving the networks. Will use trained networks\n",
    "to test some other dataset specific variables and plots, etc when they're finished, then integrate those\n",
    "into the main workflow. \n",
    "\n",
    "TODO ASAP!!!!!!\n",
    "Make a checkpoint from the trained & saved dominoe_sequencer results to continue training etc.\n",
    "\"\"\"\n",
    "\n",
    "# put differences in parameters in logger!!!\n",
    "# think more carefully about how to handle the ignore index for reward computation.....\n",
    "# add special messages for curricula phases\n",
    "\n",
    "# handling of checkpoints for curriculum learning is kinda rough...\n",
    "# -- I think I can make a central system for all curricula that will handle all of this\n",
    "\n",
    "# I need a smarter \"load_experiment\" update prms / exp.args method... (for example probably shouldn't update the checkpointing parameters)\n",
    "# And in general need better analysis tools for rebuilding networks and rerunning data processing\n",
    "\n",
    "# consider updating masking methods (so that I can have a valid hook point after applying a mask)\n",
    "\n",
    "# Interpretability Tools:\n",
    "# https://github.com/TransformerLensOrg/TransformerLens?tab=readme-ov-file --- this has a really nice looking reading list...\n",
    "# https://transformer-circuits.pub/2021/garcon/index.html\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from ptrseq.experiments import get_experiment\n",
    "from ptrseq.datasets import get_dataset\n",
    "from ptrseq.experiments import get_experiment\n",
    "from ptrseq.utils import get_scheduler, build_args, stack_results, get_dictionary_differences\n",
    "from ptrseq.networks.net_utils import forward_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24fb465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4035,  0.9901,  1.3796, -1.2110, -1.1152, -0.2425,  0.5941,\n",
      "          -1.3056,  0.0769, -1.4911,  0.2296,  2.1306,  0.7261, -0.6109,\n",
      "           0.0776, -0.6318],\n",
      "         [ 1.7410,  0.5438, -0.4212, -0.5027,  0.4249, -0.3977,  0.6491,\n",
      "          -0.8524,  0.9294, -1.8993, -2.0965,  0.5857,  0.1425, -0.4267,\n",
      "           1.0089,  0.5714]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.4035,  0.9901,  1.3796, -1.2110, -1.1152, -0.2425,  0.5941,\n",
      "          -1.3056,  0.0769, -1.4911,  0.2296,  2.1306,  0.7261, -0.6109,\n",
      "           0.0776, -0.6318],\n",
      "         [ 1.7410,  0.5438, -0.4212, -0.5027,  0.4249, -0.3977,  0.6491,\n",
      "          -0.8524,  0.9294, -1.8993, -2.0965,  0.5857,  0.1425, -0.4267,\n",
      "           1.0089,  0.5714]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from ptrseq.networks.attention_modules import get_attention_layer\n",
    "from ptrseq.networks.transformer_modules import get_transformer_layer\n",
    "\n",
    "import torch\n",
    "from transformer_lens.hook_points import HookedRootModule\n",
    "\n",
    "transformer = get_transformer_layer(16, 4, 1, False, False, False, 0, False, False)\n",
    "\n",
    "input = torch.rand(1, 2, 16)\n",
    "out = transformer(input)\n",
    "print(out)\n",
    "\n",
    "out, cache = transformer.run_with_cache(input)\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3996b397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention._query_hook torch.Size([1, 2, 16])\n",
      "attention._key_hook torch.Size([1, 2, 16])\n",
      "attention._value_hook torch.Size([1, 2, 16])\n",
      "attention._attention_hook torch.Size([4, 2, 2])\n",
      "attention._head_output_hook torch.Size([1, 2, 4, 4])\n",
      "attention._unify_head_hook torch.Size([1, 2, 16])\n",
      "_attention_hook torch.Size([1, 2, 16])\n",
      "_mlp_pre_hook torch.Size([1, 2, 16])\n",
      "_mlp_post_hook torch.Size([1, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "for k, v in cache.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14219930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "03b33b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.280393123626709\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "experiment = \"ptr_arch_comp\"\n",
    "args = dict(task=\"dominoe_sorter\", encoder_method=\"attention\", decoder_method=\"attention\", replicates=\"3\", embedding_bias=\"False\")\n",
    "exp = get_experiment(experiment, build=True, args=build_args(kvargs=args))\n",
    "\n",
    "results = exp.load_experiment(use_saved_prms=False, verbose=True)\n",
    "dataset = exp.prepare_dataset()\n",
    "\n",
    "# input dimensionality\n",
    "input_dim = dataset.get_input_dim()\n",
    "context_parameters = dataset.get_context_parameters()\n",
    "\n",
    "# create networks\n",
    "nets, optimizers, prms = exp.create_networks(input_dim, context_parameters)\n",
    "nets = exp.load_networks(nets)\n",
    "for net in nets:\n",
    "    net.eval()\n",
    "\n",
    "# prepare dataset parameters\n",
    "parameters = exp.make_train_parameters(dataset, train=False)\n",
    "dominoes = dataset.get_dominoe_set(parameters[\"train\"])\n",
    "\n",
    "t = time()\n",
    "\n",
    "# create example batch\n",
    "batch = dataset.generate_batch(**(parameters | {\"batch_size\": 1024}))\n",
    "\n",
    "# run data through the network\n",
    "max_possible_output = parameters.get(\"max_possible_output\")  # this is the maximum number of outputs ever\n",
    "scores, choices = forward_batch(nets, batch, max_possible_output, temperature=1.0, thompson=False)\n",
    "\n",
    "# measure rewards\n",
    "rewards = [dataset.reward_function(choice, batch) for choice in choices]\n",
    "\n",
    "print(time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ca72c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        # self.conv1 = nn.Conv2d(1, 2, kernel_size=5)\n",
    "        # self.conv2 = nn.Conv2d(2, 5, kernel_size=5)\n",
    "        # self.conv = nn.Sequential(self.conv1, nn.ReLU(), self.conv2, nn.ReLU())\n",
    "        # self.fc1 = nn.Linear(80, 10)\n",
    "        # self.fc2 = nn.Linear(10, 2)\n",
    "        # self.linear = nn.Sequential(self.fc1, nn.ReLU(), self.fc2)\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 2, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 5, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(80, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        # x = self.conv(x)\n",
    "        # x = x.view(-1, 320)\n",
    "        # x = self.linear(x)\n",
    "        # return x\n",
    "    \n",
    "class HookedModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(HookedModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.cache = {}\n",
    "        self._add_hooks()\n",
    "        self.store_hidden = False\n",
    "\n",
    "    def _add_hooks(self):\n",
    "        self._layer_to_name = {}\n",
    "        for name, layer in self.model.named_children():\n",
    "            self._layer_to_name[layer] = name\n",
    "            if True: #not isinstance(layer, nn.Sequential):\n",
    "                layer.register_forward_hook(self._forward_hook)\n",
    "    \n",
    "    def _forward_hook(self, layer, input, output):\n",
    "        if self.store_hidden:\n",
    "            self.cache[self._layer_to_name[layer]] = output\n",
    "\n",
    "    @contextmanager\n",
    "    def _handle_cache(self, store_hidden):\n",
    "        self.store_hidden = store_hidden\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            self.store_hidden = False\n",
    "\n",
    "    def forward(self, x, store_hidden=False):\n",
    "        with self._handle_cache(store_hidden):\n",
    "            output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "net = CustomModel()\n",
    "hnet = HookedModel(deepcopy(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cb1347f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_submodules(module, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Recursively collects all submodules of a given nn.Module.\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): The parent module.\n",
    "\n",
    "    Returns:\n",
    "        List[nn.Module]: A list of all submodules.\n",
    "    \"\"\"\n",
    "    submodules = []\n",
    "    for name, submodule in module.named_children():\n",
    "        full_name = f\"{prefix}.{name}\" if prefix else name\n",
    "        submodules.append(full_name)\n",
    "        submodules.extend(get_all_submodules(submodule, prefix=full_name))\n",
    "    return submodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1440727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 embedding Linear(in_features=20, out_features=128, bias=False)\n",
      "Linear\n"
     ]
    }
   ],
   "source": [
    "for idx, (name, module) in enumerate(nets[0].named_modules()):\n",
    "    if idx==0: continue\n",
    "    print(idx, name, module)\n",
    "    print(module.__class__.__name__)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "26fe4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnet = HookedModel(nets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f6f3d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-6.4133e-05, -1.9241e+01, -1.9159e+01,  ..., -1.9241e+01,\n",
       "           -1.9241e+01, -1.9241e+01],\n",
       "          [-6.9578e+01, -1.9578e+01, -1.8302e+01,  ..., -1.9578e+01,\n",
       "           -1.9578e+01, -1.9578e+01],\n",
       "          [-6.2098e+01, -1.2097e+01, -3.6478e+00,  ..., -1.2098e+01,\n",
       "           -1.2098e+01, -1.2087e+01],\n",
       "          ...,\n",
       "          [-6.2991e+01, -6.2991e+01, -6.2991e+01,  ..., -1.0136e+01,\n",
       "           -6.2991e+01, -6.2991e+01],\n",
       "          [-5.9735e+01, -5.9735e+01, -5.9735e+01,  ..., -2.9221e+00,\n",
       "           -5.9735e+01, -5.9735e+01],\n",
       "          [-5.7243e+01, -5.7243e+01, -5.7243e+01,  ...,  0.0000e+00,\n",
       "           -5.7243e+01, -5.7243e+01]],\n",
       " \n",
       "         [[-1.4718e+01, -1.3524e+01, -1.4718e+01,  ..., -2.3961e-05,\n",
       "           -1.4718e+01, -1.0971e+01],\n",
       "          [-7.4645e+00, -3.9639e+00, -7.4645e+00,  ..., -5.7465e+01,\n",
       "           -7.4625e+00, -6.0858e-02],\n",
       "          [-9.0136e+00, -1.5847e+00, -9.0136e+00,  ..., -5.9014e+01,\n",
       "           -8.9822e+00, -5.9014e+01],\n",
       "          ...,\n",
       "          [-1.7812e-01, -5.9514e+01, -5.9514e+01,  ..., -5.9514e+01,\n",
       "           -5.9514e+01, -5.9514e+01],\n",
       "          [-6.1384e+01, -6.1384e+01, -6.1384e+01,  ..., -6.1384e+01,\n",
       "           -6.1384e+01, -6.1384e+01],\n",
       "          [-5.8790e+01, -5.8790e+01, -5.8790e+01,  ..., -5.8790e+01,\n",
       "           -5.8790e+01, -5.8790e+01]],\n",
       " \n",
       "         [[-1.7874e+01, -1.7874e+01, -1.7721e+01,  ..., -1.7778e+01,\n",
       "           -1.7860e+01, -1.7864e+01],\n",
       "          [-1.7668e+01, -1.7669e+01, -1.6752e+01,  ..., -1.7053e+01,\n",
       "           -1.7584e+01, -1.7603e+01],\n",
       "          [-1.3226e+01, -1.3233e+01, -9.3411e+00,  ..., -1.0324e+01,\n",
       "           -1.2739e+01, -1.2833e+01],\n",
       "          ...,\n",
       "          [ 0.0000e+00, -1.8403e+01, -6.8618e+01,  ..., -6.8618e+01,\n",
       "           -6.8618e+01, -6.8618e+01],\n",
       "          [-5.5390e+01, -8.4834e-02, -5.5390e+01,  ..., -5.5390e+01,\n",
       "           -5.5390e+01, -5.5390e+01],\n",
       "          [-5.3683e+01, -5.3683e+01, -5.3683e+01,  ..., -5.3683e+01,\n",
       "           -5.3683e+01, -5.3683e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.0480e+01, -2.0480e+01, -2.0480e+01,  ..., -2.0480e+01,\n",
       "            0.0000e+00, -2.0480e+01],\n",
       "          [-1.2278e+01, -1.2278e+01, -1.2278e+01,  ..., -1.2278e+01,\n",
       "           -6.2279e+01, -1.2278e+01],\n",
       "          [-1.8029e+01, -1.8032e+01, -1.8024e+01,  ..., -1.8027e+01,\n",
       "           -6.8032e+01, -1.8032e+01],\n",
       "          ...,\n",
       "          [-5.8165e+01, -9.5928e-02, -5.8165e+01,  ..., -5.8165e+01,\n",
       "           -5.8165e+01, -5.8165e+01],\n",
       "          [-5.9658e+01, -5.9658e+01, -5.9658e+01,  ..., -5.9658e+01,\n",
       "           -5.9658e+01, -5.9658e+01],\n",
       "          [-5.5328e+01, -5.5328e+01, -5.5328e+01,  ..., -5.5328e+01,\n",
       "           -5.5328e+01, -5.5328e+01]],\n",
       " \n",
       "         [[-1.7975e+01, -1.7551e+01, -1.7979e+01,  ..., -1.1921e-06,\n",
       "           -1.7979e+01, -1.7980e+01],\n",
       "          [-9.3110e+00, -7.6627e+00, -9.3300e+00,  ..., -5.9330e+01,\n",
       "           -9.3301e+00, -9.3301e+00],\n",
       "          [-1.2937e+01, -9.9036e+00, -1.2984e+01,  ..., -6.2984e+01,\n",
       "           -1.2984e+01, -1.2984e+01],\n",
       "          ...,\n",
       "          [-6.1953e+01, -6.1953e+01, -6.1953e+01,  ..., -6.1953e+01,\n",
       "           -6.1953e+01, -1.0336e+01],\n",
       "          [-6.3557e+01, -6.3557e+01, -6.3557e+01,  ..., -6.3557e+01,\n",
       "           -6.3557e+01, -8.7713e+00],\n",
       "          [-5.7829e+01, -5.7829e+01, -5.7829e+01,  ..., -5.7829e+01,\n",
       "           -5.7829e+01,  0.0000e+00]],\n",
       " \n",
       "         [[-1.1782e+01, -6.3142e+00, -1.1782e+01,  ..., -1.1782e+01,\n",
       "           -1.1782e+01, -2.0785e-03],\n",
       "          [-1.3399e+01, -7.4335e-03, -1.3399e+01,  ..., -1.3399e+01,\n",
       "           -1.3399e+01, -6.3399e+01],\n",
       "          [-2.0243e+01, -7.0243e+01, -2.0243e+01,  ..., -2.0243e+01,\n",
       "           -2.0243e+01, -7.0243e+01],\n",
       "          ...,\n",
       "          [-6.2397e+01, -6.2397e+01, -6.2397e+01,  ..., -6.2518e-04,\n",
       "           -9.0397e+00, -6.2397e+01],\n",
       "          [-5.9357e+01, -5.9357e+01, -5.9357e+01,  ..., -5.9357e+01,\n",
       "           -1.8713e+00, -5.9357e+01],\n",
       "          [-5.6499e+01, -5.6499e+01, -5.6499e+01,  ..., -5.6499e+01,\n",
       "            0.0000e+00, -5.6499e+01]]], device='cuda:0'),\n",
       " tensor([[ 0,  7,  4,  ...,  3,  6,  9],\n",
       "         [ 9, 11,  5,  ...,  0,  3,  6],\n",
       "         [ 4,  8,  6,  ...,  0,  1,  5],\n",
       "         ...,\n",
       "         [10,  7,  6,  ...,  1,  8,  5],\n",
       "         [ 9,  3,  7,  ...,  8,  6, 11],\n",
       "         [11,  1,  7,  ...,  9,  8, 10]], device='cuda:0'))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hnet(batch[\"input\"], store_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "32ceae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embedding', 'decoder'])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hnet.cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fee461bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['layers'])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 12, 12)\n",
    "out = net(x)\n",
    "hout = hnet(x, store_hidden=True)\n",
    "print(hnet.cache.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "177fcc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0494, -0.2356]])\n",
      "tensor([[ 0.0494, -0.2356]])\n"
     ]
    }
   ],
   "source": [
    "print(hnet.cache[\"layers\"])\n",
    "print(hout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
