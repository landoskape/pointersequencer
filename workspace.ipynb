{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52362dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pointer Immediate Tasks:\n",
    "- Run an experiment where I take trained pointer networks and transition them to a dominoe based value \n",
    "function and a gamma < 1, and show that they can learn to prioritize playing high value dominoes first. Then...\n",
    "-  Add the context vector that encodes the number of turns left (with uncertainty?)\n",
    "    - so the full pointer network will get an extra context input that describes how many turns are left\n",
    "    - 0 rewards will be given after the possible turns are over\n",
    "    - so the network will have to learn to get as much value out as quickly as possible\n",
    "-  Also apply these networks to the vehicle routing problem?\n",
    "-  Analyze encoding space of pointer networks...\n",
    "-  Do the encoder swap of different pointer layers...\n",
    "-  Does the speed of learning for the different networks on the sequencer task come from true performance or just sensitivity to the temperature? \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "TODO For refactoring\n",
    "at the moment there is no flexibility on the loss function control for the supervised dataset!!!!\n",
    "\n",
    "Add mechanism for printing the arguments used to build a pointernetwork so the user can see what they did. \n",
    "Add mechanism for storing hidden parameters to entire pointer network\n",
    "\n",
    "Add documentation of baseline updates and performance etc\n",
    "Add some dataset specific summary plots and integrate into plotting code? \n",
    "Get the supervised learning methods working for each dataset and task\n",
    "Checkpointing, figure making, logging, etc\n",
    "\n",
    "it worked!!! now trying without embedding bias...\n",
    "it works without embedding bias. It works (with different speeds per pointer layer!) with lower train temperature\n",
    " (but of course that could be because of differential sensitivity to temperature..., should test that directly)\n",
    "now trying with 1 encoding layer. \n",
    "\n",
    ":)\n",
    "\n",
    "\n",
    "TODO: \n",
    "DOMINOES SEQUENCER Comparison of max to real reward:\n",
    "- Add target to batch (can do post-hoc, even if not requested)\n",
    "- Measure reward of target\n",
    "- Add a 2D vector comparing max and real reward for each batch element!!\n",
    "\n",
    "TSP Distance Traveled:\n",
    "- Explicitly measure the distance traveled by the agent in the TSP task\n",
    "- Compare to Held-Karp Solution\n",
    "\n",
    "\n",
    "TODO ASAP!!!!!!\n",
    "- Get test result plots in there for good plotting, then start running experiments with different parameters\n",
    "  so you can save / see the results!!!\n",
    "\"\"\"\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c715a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8404c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "import torch\n",
    "from ptrseq.datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78fe2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "dists\n",
      "init\n",
      "num_cities\n",
      "coord_dims\n",
      "batch_size\n",
      "return_target\n",
      "ignore_index\n",
      "threads\n",
      "target\n"
     ]
    }
   ],
   "source": [
    "task = \"tsp\"\n",
    "dataset = get_dataset(task, build=True, num_cities=10)\n",
    "batch = dataset.generate_batch(batch_size=4, return_target=True)\n",
    "\n",
    "for k in batch.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2ff400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 7, 4, 2, 5, 6, 1, 0, 8, 3],\n",
       "        [1, 9, 5, 6, 2, 0, 4, 8, 3, 7],\n",
       "        [6, 3, 1, 9, 2, 0, 7, 5, 8, 4],\n",
       "        [7, 5, 3, 9, 1, 6, 8, 2, 4, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f70f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 7 to 6 with reward 0.15, distance: 0.15\n",
      "From 6 to 9 with reward 0.32, distance: 0.32\n",
      "From 9 to 0 with reward 0.34, distance: 0.34\n",
      "From 0 to 5 with reward 0.57, distance: 0.57\n",
      "From 5 to 8 with reward 0.29, distance: 0.29\n",
      "From 8 to 3 with reward 0.28, distance: 0.28\n",
      "From 3 to 2 with reward 0.56, distance: 0.56\n",
      "From 2 to 4 with reward 0.48, distance: 0.48\n",
      "From 4 to 1 with reward 0.40, distance: 0.40\n"
     ]
    }
   ],
   "source": [
    "reward = dataset.reward_function(batch[\"target\"], batch)\n",
    "\n",
    "ib = 0\n",
    "prev = batch[\"init\"][ib]\n",
    "for i, s in enumerate(batch[\"target\"][ib]):\n",
    "    if i==(batch[\"target\"].size(1)-1):\n",
    "        add_dist = batch[\"dists\"][ib][s, batch[\"init\"][ib]]\n",
    "    else:\n",
    "        add_dist = 0\n",
    "    print(f\"From {prev} to {s} with reward {-reward[ib][i]:.2f}, distance: {batch['dists'][ib][prev, s] + add_dist :.2f}\")\n",
    "    prev = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865fb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b81df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "highest_dominoe = 9\n",
    "dataset = DominoeDataset(\"sequencer\", highest_dominoe, hand_size=8, return_target=True)\n",
    "\n",
    "batch = dataset.generate_batch(train=False, batch_size=4, value_method=\"length\")\n",
    "dominoes = dataset.get_dominoe_set(train=False)\n",
    "\n",
    "target_as_choice = batch[\"target\"].clone()\n",
    "target_as_choice[target_as_choice==-1] = dataset.prms[\"hand_size\"]\n",
    "\n",
    "reward, direction = dataset._measurereward_sequencer(target_as_choice, batch, return_direction=True)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80eea3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n",
      "tensor([6., 8.]) reverse\n",
      "tensor([2., 6.]) reverse\n",
      "tensor([2., 8.]) forward\n",
      "tensor([1., 8.]) reverse\n",
      "tensor([1., 4.]) forward\n",
      "tensor([-1., -1.]) reverse\n",
      "tensor([-1., -1.]) reverse\n",
      "tensor([-1., -1.]) reverse\n",
      "tensor([-1., -1.]) reverse\n"
     ]
    }
   ],
   "source": [
    "ib = 1\n",
    "hand = dominoes[batch[\"selection\"][ib]]\n",
    "hand_null = torch.cat([hand, -torch.ones((1, 2))], dim=0)\n",
    "\n",
    "print(batch[\"available\"][ib])\n",
    "for c, d in zip(target_as_choice[ib], direction[ib]):\n",
    "    print(hand_null[c], \"forward\" if d==0 else \"reverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
