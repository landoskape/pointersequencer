{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52362dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pointer Immediate Tasks:\n",
    "- Run an experiment where I take trained pointer networks and transition them to a dominoe based value \n",
    "function and a gamma < 1, and show that they can learn to prioritize playing high value dominoes first. Then...\n",
    "-  Add the context vector that encodes the number of turns left (with uncertainty?)\n",
    "    - so the full pointer network will get an extra context input that describes how many turns are left\n",
    "    - 0 rewards will be given after the possible turns are over\n",
    "    - so the network will have to learn to get as much value out as quickly as possible\n",
    "-  Also apply these networks to the vehicle routing problem?\n",
    "-  Analyze encoding space of pointer networks...\n",
    "-  Do the encoder swap of different pointer layers...\n",
    "-  Does the speed of learning for the different networks on the sequencer task come from true performance or just sensitivity to the temperature? \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "We can speed up some of the processing by doing all networks output in a list at once-- for example for reward computation. I think \n",
    "the sequencer is slower because measuring reward takes a long time...\n",
    "\n",
    "Add mechanism for printing the arguments used to build a pointernetwork so the user can see what they did. \n",
    "Add mechanism for storing hidden parameters to entire pointer network\n",
    "\n",
    "Add documentation of baseline updates and performance etc\n",
    "Add some dataset specific summary plots and integrate into plotting code? \n",
    "Get the supervised learning methods working for each dataset and task\n",
    "Checkpointing, figure making, logging, etc\n",
    "\n",
    "it worked!!! now trying without embedding bias...\n",
    "it works without embedding bias. It works (with different speeds per pointer layer!) with lower train temperature\n",
    " (but of course that could be because of differential sensitivity to temperature..., should test that directly)\n",
    "now trying with 1 encoding layer. \n",
    "\n",
    ":)\n",
    "\n",
    "TODO: \n",
    "DOMINOES SEQUENCER Comparison of max to real reward:\n",
    "- Add target to batch (can do post-hoc, even if not requested)\n",
    "- Measure reward of target\n",
    "- Add a 2D vector comparing max and real reward for each batch element!!\n",
    "\n",
    "TSP Distance Traveled:\n",
    "- Explicitly measure the distance traveled by the agent in the TSP task\n",
    "- Compare to Held-Karp Solution\n",
    "\n",
    "\n",
    "TODO ASAP!!!!!!\n",
    "I'm running experiments with attention only pointers and saving the networks. Will use trained networks\n",
    "to test some other dataset specific variables and plots, etc when they're finished, then integrate those\n",
    "into the main workflow. \n",
    "\n",
    "TODO ASAP!!!!!!\n",
    "Make a checkpoint from the trained & saved dominoe_sequencer results to continue training etc.\n",
    "\"\"\"\n",
    "\n",
    "# put differences in parameters in logger!!!\n",
    "# think more carefully about how to handle the ignore index for reward computation.....\n",
    "# add special messages for curricula phases\n",
    "\n",
    "# handling of checkpoints for curriculum learning is kinda rough...\n",
    "# -- I think I can make a central system for all curricula that will handle all of this\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from ptrseq.experiments import get_experiment\n",
    "from ptrseq.datasets import get_dataset\n",
    "from ptrseq.experiments import get_experiment\n",
    "from ptrseq.utils import get_scheduler, build_args, stack_results, get_dictionary_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ec7a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: found unique parameters in checkpoint: {'d': 4}\n",
      "WARNING: found unique parameters in current run: {'e': 5}\n",
      "WARNING: found different parameter values in checkpoint: {'a': (1, 5)}\n"
     ]
    }
   ],
   "source": [
    "dict1 = dict(a=1, b=2, c=3, d=4)\n",
    "dict2 = dict(a=5, b=2, c=3, e=5)\n",
    "ckpt_unique, curr_unique, diff_values = get_dictionary_differences(dict1, dict2)\n",
    "if ckpt_unique:\n",
    "    print(f\"WARNING: found unique parameters in checkpoint: {ckpt_unique}\")\n",
    "if curr_unique:\n",
    "    print(f\"WARNING: found unique parameters in current run: {curr_unique}\")\n",
    "if diff_values:\n",
    "    print(f\"WARNING: found different parameter values in checkpoint: {diff_values}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b33b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"ptr_arch_comp\"\n",
    "task = \"dominoe_sorter\"\n",
    "\n",
    "exp = get_experiment(experiment, build=True, args=build_args(task))\n",
    "results = exp.load_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
