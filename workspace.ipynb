{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52362dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pointer Immediate Tasks:\n",
    "- Run an experiment where I take trained pointer networks and transition them to a dominoe based value \n",
    "function and a gamma < 1, and show that they can learn to prioritize playing high value dominoes first. Then...\n",
    "-  Add the context vector that encodes the number of turns left (with uncertainty?)\n",
    "    - so the full pointer network will get an extra context input that describes how many turns are left\n",
    "    - 0 rewards will be given after the possible turns are over\n",
    "    - so the network will have to learn to get as much value out as quickly as possible\n",
    "-  Also apply these networks to the vehicle routing problem?\n",
    "-  Analyze encoding space of pointer networks...\n",
    "-  Do the encoder swap of different pointer layers...\n",
    "-  Does the speed of learning for the different networks on the sequencer task come from true performance or just sensitivity to the temperature? \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "We can speed up some of the processing by doing all networks output in a list at once-- for example for reward computation. I think \n",
    "the sequencer is slower because measuring reward takes a long time...\n",
    "\n",
    "Add mechanism for printing the arguments used to build a pointernetwork so the user can see what they did. \n",
    "Add mechanism for storing hidden parameters to entire pointer network\n",
    "\n",
    "Add documentation of baseline updates and performance etc\n",
    "Add some dataset specific summary plots and integrate into plotting code? \n",
    "Get the supervised learning methods working for each dataset and task\n",
    "Checkpointing, figure making, logging, etc\n",
    "\n",
    "it worked!!! now trying without embedding bias...\n",
    "it works without embedding bias. It works (with different speeds per pointer layer!) with lower train temperature\n",
    " (but of course that could be because of differential sensitivity to temperature..., should test that directly)\n",
    "now trying with 1 encoding layer. \n",
    "\n",
    ":)\n",
    "\n",
    "TODO: \n",
    "DOMINOES SEQUENCER Comparison of max to real reward:\n",
    "- Add target to batch (can do post-hoc, even if not requested)\n",
    "- Measure reward of target\n",
    "- Add a 2D vector comparing max and real reward for each batch element!!\n",
    "\n",
    "TSP Distance Traveled:\n",
    "- Explicitly measure the distance traveled by the agent in the TSP task\n",
    "- Compare to Held-Karp Solution\n",
    "\n",
    "\n",
    "TODO ASAP!!!!!!\n",
    "I'm running experiments with attention only pointers and saving the networks. Will use trained networks\n",
    "to test some other dataset specific variables and plots, etc when they're finished, then integrate those\n",
    "into the main workflow. \n",
    "\n",
    "TODO ASAP!!!!!!\n",
    "Make a checkpoint from the trained & saved dominoe_sequencer results to continue training etc.\n",
    "\"\"\"\n",
    "\n",
    "# put differences in parameters in logger!!!\n",
    "# think more carefully about how to handle the ignore index for reward computation.....\n",
    "# add special messages for curricula phases\n",
    "\n",
    "# handling of checkpoints for curriculum learning is kinda rough...\n",
    "# -- I think I can make a central system for all curricula that will handle all of this\n",
    "\n",
    "# I need a smarter \"load_experiment\" update prms / exp.args method... (for example probably shouldn't update the checkpointing parameters)\n",
    "# And in general need better analysis tools for rebuilding networks and rerunning data processing\n",
    "\n",
    "\n",
    "# Interpretability Tools:\n",
    "# https://github.com/TransformerLensOrg/TransformerLens?tab=readme-ov-file --- this has a really nice looking reading list...\n",
    "# https://transformer-circuits.pub/2021/garcon/index.html\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from ptrseq.experiments import get_experiment\n",
    "from ptrseq.datasets import get_dataset\n",
    "from ptrseq.experiments import get_experiment\n",
    "from ptrseq.utils import get_scheduler, build_args, stack_results, get_dictionary_differences\n",
    "from ptrseq.networks.net_utils import forward_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03b33b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2621960639953613\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "experiment = \"ptr_arch_comp\"\n",
    "args = dict(task=\"dominoe_sorter\", encoder_method=\"attention\", decoder_method=\"attention\", replicates=\"3\", embedding_bias=\"False\")\n",
    "exp = get_experiment(experiment, build=True, args=build_args(kvargs=args))\n",
    "\n",
    "results = exp.load_experiment(use_saved_prms=False, verbose=True)\n",
    "dataset = exp.prepare_dataset()\n",
    "\n",
    "# input dimensionality\n",
    "input_dim = dataset.get_input_dim()\n",
    "context_parameters = dataset.get_context_parameters()\n",
    "\n",
    "# create networks\n",
    "nets, optimizers, prms = exp.create_networks(input_dim, context_parameters)\n",
    "nets = exp.load_networks(nets)\n",
    "for net in nets:\n",
    "    net.eval()\n",
    "\n",
    "# prepare dataset parameters\n",
    "parameters = exp.make_train_parameters(dataset, train=False)\n",
    "dominoes = dataset.get_dominoe_set(parameters[\"train\"])\n",
    "\n",
    "t = time()\n",
    "\n",
    "# create example batch\n",
    "batch = dataset.generate_batch(**(parameters | {\"batch_size\": 1024}))\n",
    "\n",
    "# run data through the network\n",
    "max_possible_output = parameters.get(\"max_possible_output\")  # this is the maximum number of outputs ever\n",
    "scores, choices = forward_batch(nets, batch, max_possible_output, temperature=1.0, thompson=False)\n",
    "\n",
    "# measure rewards\n",
    "rewards = [dataset.reward_function(choice, batch) for choice in choices]\n",
    "\n",
    "print(time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72c5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
